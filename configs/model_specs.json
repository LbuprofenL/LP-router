{
  "facebook-opt-1.3b": {
    "params_b": 1.3,
    "bytes_per_param": 2,
    "arch": {
      "hidden_size": 2048,
      "num_hidden_layers": 24,
      "num_attention_heads": 32,
      "num_key_value_heads": 32,
      "intermediate_size": 8192,
      "bytes_per_elem": 2
    }
  },
  "qwen3-8b": {
    "params_b": 8.2,
    "bytes_per_param": 2,
    "arch": {
      "hidden_size": 4096,
      "num_hidden_layers": 36,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "intermediate_size": 22016,
      "bytes_per_elem": 2
    }
  }
}

